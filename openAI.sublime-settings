{
    // The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code. [Learn more](https://beta.openai.com/docs/models).
    // Doesn't affects editing mode.
    "model": "text-davinci-003",
    // Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.
    "temperature": 0.7,
    // The maximum number of tokens to generate.
    // Requests can use up to 2,048 or 4,000 tokens shared between prompt and completion.
    // The exact limit varies by model.
    // (One token is roughly 4 characters for normal English text)
    // Not affects editing mode.
    "max_tokens": 256,
    // Controls diversity via nucleus sampling:
    // 0.5 means half of all likelihood-weighted options are considered.
    "top_p": 1,
    // Controls the minimum height of the debugger output panels in lines
    "frequency_penalty": 0,
    // Some new features are locked behind this flag
    "presence_penalty": 0,
    // placeholder for insert mode. You should to put it in the place where you want to code to be prompted.
    // e.g.
    // def get_bitcoin_price():
    //    [insert]
    //    print(bitcoin_price)
    "placeholder": "[insert]",
    // Your openAI token
    "token": "",
    // Whether to ask the AI to format its answers with multimarkdown markup
    // Affects only completion command.
    "multimarkdown": false
}