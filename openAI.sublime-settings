{
    // The model which will generate the completion.
    // Some models are suitable for natural language tasks, others specialize in code.
    // Learn more at https://beta.openai.com/docs/models
    // Does not affect editing mode.
    "model": "text-davinci-003",

    // The model which will generate the completion.
    // Some models are suitable for natural language tasks, others specialize in code.
    // Learn more at https://beta.openai.com/docs/models
    // Does not affect editing mode.
    "chat_model": "gpt-3.5-turbo",

    // Controls randomness: Lowering results in less random completions.
    // As the temperature approaches zero, the model will become deterministic and repetitive.
    "temperature": 0.7,

    // The maximum number of tokens to generate.
    // Requests can use up to 2,048 or 4,000 tokens shared between prompt and completion.
    // The exact limit varies by model.
    // (One token is roughly 4 characters for normal English text)
    // Does not affect editing mode.
    "max_tokens": 256,

    // Controls diversity via nucleus sampling:
    // 0.5 means half of all likelihood-weighted options are considered.
    "top_p": 1,

    // Controls the minimum height of the debugger output panels in lines.
    "frequency_penalty": 0,

    // Some new features are locked behind this flag.
    "presence_penalty": 0,

    // Placeholder for insert mode. You should to put it where you want the suggestion to be inserted.
    // e.g. (python)
    // def get_bitcoin_price():
    //    [insert]
    //    print(bitcoin_price)
    "placeholder": "[insert]",

    // Your openAI token
    "token": "",

    // Apply Sublime Text markdown syntax highligh to OpenAI completion output panel text.
    // Affects only `chat_completion` command.
    "markdown": true,

    // Minimum amount of characters selected to perform completion.
    // Does not affect completion command if the "output_panel" setting is true.
    "minimum_selection_length": 20
}
